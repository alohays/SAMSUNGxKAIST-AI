{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cyclegan_horse2zebra_assign.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Yz80rPMZKObK"
      },
      "source": [
        "# Aquire dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfUX-Y7sQQV9",
        "colab_type": "text"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhZ6anWZ6G6Z",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxo34j6Qdscq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('./logs'):\n",
        "    os.makedirs('./logs')\n",
        "if not os.path.exists('./datasets'):\n",
        "    os.makedirs('./datasets')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb8ujxWx2oka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!bash ./download_cyclegan_dataset.sh horse2zebra"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTHemRjFQQWC",
        "colab_type": "text"
      },
      "source": [
        "# Model definition & Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aAu_qett4H4v",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional\n",
        "import torch\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid, save_image\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchsummary import summary\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ufcX0A2Y4J_t",
        "colab": {}
      },
      "source": [
        "img_size = 256 # 이미지 사이즈 \n",
        "channels = 3\n",
        "ngf = 32 # G channels after first layer\n",
        "ndf = 64 # D channels after first layer\n",
        "\n",
        "epochs = 15 # 200번이 충분하지만, 시간단축을 위해 15번으로 조정\n",
        "batch_size = 4 # batch size\n",
        "lambda_X = 10\n",
        "lambda_Y = 10\n",
        "lambda_identity_X = 0.5\n",
        "lambda_identity_Y = 0.5\n",
        "lr = 0.0002 # learning rate\n",
        "betas = (0.5, 0.999)\n",
        "\n",
        "mean_init = 0.0\n",
        "std_init = 0.02"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "roIYTK_rvNJP",
        "colab": {}
      },
      "source": [
        "# Cuda stuff\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(\"Device is \" + str(device) + \".\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M086leYqCAV",
        "colab_type": "text"
      },
      "source": [
        "# CycleGAN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hPy-hIOP43Ux",
        "colab": {}
      },
      "source": [
        "# ResidualBlock 설계\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, c):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        \n",
        "        block = [nn.ReflectionPad2d(1),\n",
        "                 nn.Conv2d(c, c, 3, 1, 0),\n",
        "                 nn.InstanceNorm2d(c),\n",
        "                 nn.ReLU(),\n",
        "                 nn.ReflectionPad2d(1),\n",
        "                 nn.Conv2d(c, c, 3, 1, 0),\n",
        "                 nn.InstanceNorm2d(c)]\n",
        "        \n",
        "        self.block = nn.Sequential(*block)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        return ????????????????"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7SijtRQW8aGv",
        "colab": {}
      },
      "source": [
        "# Generator 설계\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        # Encoding\n",
        "        model = []\n",
        "        model += [nn.ReflectionPad2d(4),\n",
        "                  nn.Conv2d(3, ngf, 9, 1, 0),\n",
        "                  nn.InstanceNorm2d(ngf),\n",
        "                  nn.ReLU()]\n",
        "        model += [nn.Conv2d(ngf, ngf*2, 4, 2, 1),\n",
        "                  nn.InstanceNorm2d(ngf*2),\n",
        "                  nn.ReLU()]\n",
        "        model += [nn.Conv2d(ngf*2, ngf*4, 4, 2, 1),\n",
        "                  nn.InstanceNorm2d(ngf*4),\n",
        "                  nn.ReLU()]\n",
        "        \n",
        "        # Transformation\n",
        "        for i in range(6):\n",
        "            model += [????????????(ngf*4)]   # 채널 수를 그대로 유지하면서 반복시켜주는 block\n",
        "        \n",
        "        # Decoding\n",
        "        model += [nn.ConvTranspose2d(ngf*4, ngf*2, ?, ?, ?), # 줄여준 H * W 를 다시 반대로 늘려주는 과정\n",
        "                  nn.InstanceNorm2d(ngf*2),\n",
        "                  nn.ReLU()]\n",
        "        model += [nn.ConvTranspose2d(ngf*2, ngf, ?, ?, ?),\n",
        "                  nn.InstanceNorm2d(ngf),\n",
        "                  nn.ReLU()]\n",
        "        model += [nn.ReflectionPad2d(4),\n",
        "                  nn.Conv2d(ngf, 3, 9, 1, 0),\n",
        "                  nn.Tanh()]\n",
        "        \n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ScqGWgOGTCnx",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        model = []\n",
        "        model += [nn.Conv2d(3, ??, ??, ??, ??),   # outputchannel : ndf, kernel: 4, stride:2 , padding : 1\n",
        "                  nn.LeakyReLU(0.2)]\n",
        "        \n",
        "        in_channels = ndf\n",
        "        out_channels = ndf*2\n",
        "        for i in range(2):\n",
        "            model += [nn.Conv2d(???????????, ??????????, 4, 2, 1),     # 어떤 변수가 input channel이 되고, 어떤 변수가 output channel이 되는가?\n",
        "                      nn.InstanceNorm2d(out_channels),\n",
        "                      nn.LeakyReLU(0.2)]\n",
        "            # 매 반복마다 channel 수가 두배가 되도록 하려면?\n",
        "            in_channels = ???????????????           \n",
        "            out_channels = ???????????????\n",
        "\n",
        "        model += [nn.Conv2d(in_channels, out_channels, 4, 1, 1),\n",
        "                  nn.InstanceNorm2d(out_channels),\n",
        "                  nn.LeakyReLU(0.2)]\n",
        "        \n",
        "        model += [nn.Conv2d(out_channels, 1, 4, 1, 1)]\n",
        "        \n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "    \n",
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUHQaDB95Kip",
        "colab_type": "text"
      },
      "source": [
        "# Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AQZCce-PjX3Z",
        "colab": {}
      },
      "source": [
        "# Dataset Code\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "class UnallignedDataset(Dataset):\n",
        "    def __init__(self, root, transform, phase='train'):\n",
        "        dir_A = os.path.join(root, phase + 'A')\n",
        "        dir_B = os.path.join(root, phase + 'B')\n",
        "        \n",
        "        self.A_paths = [os.path.join(dir_A, f) for f in os.listdir(dir_A)]\n",
        "        self.B_paths = [os.path.join(dir_B, f) for f in os.listdir(dir_B)]\n",
        "        self.A_size = len(self.A_paths)\n",
        "        self.B_size = len(self.B_paths)\n",
        "        \n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        A_path = self.A_paths[index % self.A_size]\n",
        "        B_path = self.B_paths[random.randint(0, self.B_size - 1)]\n",
        "        \n",
        "        A_img = Image.open(A_path).convert('RGB')\n",
        "        B_img = Image.open(B_path).convert('RGB')\n",
        "\n",
        "        A = self.transform(A_img)\n",
        "        B = self.transform(B_img)\n",
        "        return A, B\n",
        "    \n",
        "    def __len__(self):\n",
        "        return max(self.A_size, self.B_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pHht4nVj8n7F",
        "colab": {}
      },
      "source": [
        "# 학습을 돕기 위한 추가 테크닉 (과제를 위해 알아야할 필요는 없음) (참고: https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/75)\n",
        "\n",
        "class ImagePool():\n",
        "    def __init__(self, pool_size):\n",
        "        self.pool_size = pool_size\n",
        "        self.images = []\n",
        "        \n",
        "    def get(self, img):\n",
        "        if len(self.images) < self.pool_size:\n",
        "            self.images.append(img)\n",
        "            return img\n",
        "        else:\n",
        "            p = random.random()\n",
        "            if p > 0.5:\n",
        "                idx = random.randint(0, self.pool_size-1)\n",
        "                tmp = self.images[idx]\n",
        "                self.images[idx] = img\n",
        "                return tmp\n",
        "            else:\n",
        "                return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1_nWsNBQKhGz"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "il5CP_fDXnay",
        "colab": {}
      },
      "source": [
        "G = Generator().to(device)\n",
        "F = Generator().to(device)\n",
        "D_X = Discriminator().to(device)\n",
        "D_Y = Discriminator().to(device)\n",
        "G.weight_init(mean_init, std_init)\n",
        "F.weight_init(mean_init, std_init)\n",
        "D_X.weight_init(mean_init, std_init)\n",
        "D_Y.weight_init(mean_init, std_init)\n",
        "G.train()\n",
        "F.train()\n",
        "D_X.train()\n",
        "D_Y.train()\n",
        "\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize(img_size), transforms.CenterCrop(img_size), transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
        "train_loader = torch.utils.data.DataLoader(dataset=UnallignedDataset('datasets/horse2zebra', transform), \n",
        "                                           batch_size=batch_size, \n",
        "                                           ???????????, # dataloader 내의 data 들이 뒤섞여 있기를 바란다면?\n",
        "                                           pin_memory=True, \n",
        "                                           num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=UnallignedDataset('datasets/horse2zebra', transform, phase='test'), \n",
        "                                           batch_size=batch_size, \n",
        "                                           ???????????, # dataloader 내의 data 들이 뒤섞여 있기를 바란다면?\n",
        "                                           pin_memory=True, \n",
        "                                           num_workers=2)\n",
        "\n",
        "X_pool = ImagePool(50)\n",
        "Y_pool = ImagePool(50)\n",
        "\n",
        "mse_criterion = nn.MSELoss()\n",
        "l1_criterion = nn.L1Loss()\n",
        "\n",
        "GF_optimizer = torch.optim.Adam(list(G.parameters()) + list(F.parameters()), lr=lr, betas=betas)\n",
        "D_X_optimizer = torch.optim.Adam(D_X.parameters(), lr=lr, betas=betas)\n",
        "D_Y_optimizer = torch.optim.Adam(D_Y.parameters(), lr=lr, betas=betas)\n",
        "\n",
        "GF_scheduler = StepLR(GF_optimizer, 1, lr/100.0)\n",
        "D_X_scheduler = StepLR(D_X_optimizer, 1, lr/100.0)\n",
        "D_Y_scheduler = StepLR(D_Y_optimizer, 1, lr/100.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fykPc1sCQQWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary(G, (3, 256, 256))\n",
        "summary(D_X, (3, 256, 256))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "61scdU94hpqL",
        "colab": {}
      },
      "source": [
        "def mean(lst):\n",
        "    return sum(lst)/len(lst)\n",
        "\n",
        "# Prepare some test data, 5 of each kind\n",
        "test_data = [(x.to(device), y.to(device)) for i, (x, y) in enumerate(test_loader) if i<5]\n",
        "\n",
        "# Define target vectors\n",
        "fake_target = 0.0\n",
        "real_target = 1.0\n",
        "for epoch in range(epochs):\n",
        "    G_gan_loss_epoch = []\n",
        "    G_cycle_loss_epoch = []\n",
        "    G_ident_loss_epoch = []\n",
        "    D_X_gan_loss_epoch = []\n",
        "    \n",
        "    # Linear lr decay\n",
        "    if epoch > 99:\n",
        "        GF_scheduler.step()\n",
        "        D_X_scheduler.step()\n",
        "        D_Y_scheduler.step()\n",
        "        \n",
        "    for i, (X, Y) in enumerate(train_loader):\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "        #########################################################\n",
        "        # Update generators\n",
        "        #########################################################\n",
        "        GF_optimizer.zero_grad()\n",
        "        \n",
        "        # Translate from X to Y, check D_Y output\n",
        "        G_out = G(X)\n",
        "        D_Y_out = D_Y(G_out)\n",
        "        G_gan_loss = mse_criterion(D_Y_out, torch.ones_like(D_Y_out).to(device))\n",
        "        \n",
        "        # Translate from Y to X, check D_X output\n",
        "        F_out = F(Y)\n",
        "        D_X_out = D_X(F_out)\n",
        "        F_gan_loss = mse_criterion(D_X_out, torch.ones_like(D_X_out).to(device))\n",
        "        \n",
        "        # Translate from X to Y to X, check reconstruction error\n",
        "        X_recon = F(G_out)\n",
        "        G_cycle_loss = l1_criterion(X_recon, X) * lambda_X\n",
        "        \n",
        "        # Translate from Y to X to Y, check reconstruction error\n",
        "        Y_recon = G(F_out)\n",
        "        F_cycle_loss = l1_criterion(Y_recon, Y) * lambda_Y\n",
        "        \n",
        "        # Translate a picture from Y from X to Y, should be Y\n",
        "        Y_ident = G(Y)\n",
        "        G_ident_loss = l1_criterion(Y_ident, Y) * lambda_identity_X * lambda_X\n",
        "        \n",
        "        # Translate a picture from X from Y to X, should be X\n",
        "        X_ident = F(X)\n",
        "        F_ident_loss = l1_criterion(X_ident, X) * lambda_identity_X * lambda_Y\n",
        "        \n",
        "        GF_loss = G_cycle_loss + ?????????? + G_ident_loss + ???????????? + G_gan_loss + ??????????? \n",
        "        GF_loss.backward()\n",
        "        GF_optimizer.step()\n",
        "        \n",
        "        #########################################################\n",
        "        # Update discriminators\n",
        "        # D_Y, minimize L_D_Y = E_y (D(y) - 1) ^2 + E_x (D(x))^2\n",
        "        #########################################################\n",
        "        D_Y_optimizer.zero_grad()\n",
        "        \n",
        "        # Test D_Y with fake and real input\n",
        "        G_out = Y_pool.get(G_out)\n",
        "        D_Y_out_fake = D_Y(G_out.detach())\n",
        "        D_Y_out_real = D_Y(Y)\n",
        "        # Calculate loss\n",
        "        D_Y_loss_fake = mse_criterion(D_Y_out_fake, torch.zeros_like(D_Y_out_fake).to(device))\n",
        "        D_Y_loss_real = mse_criterion(D_Y_out_real, torch.ones_like(D_Y_out_real).to(device))\n",
        "        D_Y_gan_loss = (D_Y_loss_real + D_Y_loss_fake)*0.5\n",
        "        \n",
        "        D_Y_gan_loss.???????? # back propagation 해주기\n",
        "        D_Y_optimizer.?????? # optimizer가 한 스텝 나아가기\n",
        "        \n",
        "        #########################################################\n",
        "        # D_X, minimize L_D_X = E_x (D(x) - 1) ^2 + E_y (D(y))^2\n",
        "        #########################################################\n",
        "        D_X_optimizer.zero_grad()\n",
        "        \n",
        "        # Test D_X with fake and real input\n",
        "        F_out = X_pool.get(F_out)\n",
        "        D_X_out_fake = D_X(F_out.detach())\n",
        "        D_X_out_real = D_X(X)\n",
        "        # Calculate loss\n",
        "        D_X_loss_fake = mse_criterion(D_X_out_fake, torch.zeros_like(D_X_out_fake).to(device))\n",
        "        D_X_loss_real = mse_criterion(D_X_out_real, torch.ones_like(D_X_out_real).to(device))\n",
        "        D_X_gan_loss = (D_X_loss_real + D_X_loss_fake)*0.5\n",
        "        \n",
        "        D_X_gan_loss.???????? # back propagation 해주기\n",
        "        D_X_optimizer.?????? # optimizer가 한 스텝 나아가기\n",
        "        \n",
        "        # Save losses\n",
        "        G_gan_loss_epoch.append(G_gan_loss.item())\n",
        "        G_cycle_loss_epoch.append(G_cycle_loss.item())\n",
        "        G_ident_loss_epoch.append(G_ident_loss.item())\n",
        "        D_X_gan_loss_epoch.append(D_X_gan_loss.item())\n",
        "        \n",
        "        # Do some test output every 100 batches\n",
        "        if i % 100 == 0:\n",
        "            checkname = 'Epoch [%d/%d], Batch [%d/%d]' % (epoch+1, epochs, i, len(train_loader))\n",
        "            savename = './logs/Epoch%dBatch%d' % (epoch+1, i)\n",
        "            print(checkname)\n",
        "            \n",
        "            image_tensor = None\n",
        "            # Generate test outputs\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                G.eval()\n",
        "                F.eval()\n",
        "                for X, Y in test_data:\n",
        "                    G_out = G(X)\n",
        "                    F_out = F(Y)\n",
        "                    if image_tensor is None:\n",
        "                        image_tensor = torch.cat((X, G_out, Y, F_out), 0)\n",
        "                    else:\n",
        "                        image_tensor = torch.cat((image_tensor, X, G_out, Y, F_out), 0)\n",
        "                G.train()\n",
        "                F.train()\n",
        "            save_image(image_tensor, savename + '.png', nrow=4, padding=50)\n",
        "            \n",
        "#             save_image(image_tensor, './i.' nrow=4, padding=2, normalize=True)\n",
        "#             writer.add_image('test_images', image, i+epoch*len(train_loader))\n",
        "    \n",
        "    # Calculate mean\n",
        "    G_gan_loss_epoch = mean(G_gan_loss_epoch)\n",
        "    G_cycle_loss_epoch = mean(G_cycle_loss_epoch)\n",
        "    G_ident_loss_epoch = mean(G_ident_loss_epoch)\n",
        "    G_loss_epoch = G_gan_loss_epoch + G_cycle_loss_epoch + G_ident_loss_epoch\n",
        "    D_X_gan_loss_epoch = mean(D_X_gan_loss_epoch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ2CQ5KnQQWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(G.state_dict(), 'G.pt')\n",
        "torch.save(F.state_dict(), 'F.pt')\n",
        "torch.save(D_X.state_dict(), 'D_X.pt')\n",
        "torch.save(D_Y.state_dict(), 'D_Y.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}